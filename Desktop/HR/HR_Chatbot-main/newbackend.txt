<summary>

<header>
RepopackPy Output File
This file was generated by RepopackPy on: 2025-01-30T19:12:06.997200
</header>

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository structure
3. Repository files, each consisting of:
    - File path as an attribute
    - Full contents of the file
</file_format>

<usage_guidelines>
1. This file should be treated as read-only. Any changes should be made to the
    original repository files, not this packed version.
2. When processing this file, use the file path attributes to distinguish
    between different files in the repository.
3. Be aware that this file may contain sensitive information. Handle it with
    the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and RepopackPy's
  configuration.
- Binary files are not included in this packed representation.
</notes>

<additional_info>
For more information about RepopackPy, visit: https://github.com/abinthomasonline/repopack-py
</additional_info>

</summary>

<repository_structure>
agent.py
app.py
config.py
data\chat_history_1001.json
hardcode.py
rag_system.py
requirements.txt
test_agent.py
tools\__init__.py
tools\rag_tool.py
tools\support_ticket_tool.py
tools\ticket_tool.py
tools\vacation_tool.py
tree.py
</repository_structure>

<repository_files>

<file path="agent.py">
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.agents import create_structured_chat_agent, AgentExecutor
from langchain.tools import StructuredTool
from langchain.schema import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
import pandas as pd
from datetime import datetime
import os
from typing import Dict, List, Optional
from tools.rag_tool import RAGTool
from tools.vacation_tool import VacationTool
from tools.ticket_tool import TicketTool
import json
from pydantic import BaseModel, Field
from tools.support_ticket_tool import SupportTicketTool
from dotenv import load_dotenv
import config

class VacationRequestSchema(BaseModel):
    employee_id: str = Field(description="The ID of the employee requesting vacation")
    start_date: str = Field(description="The start date of the vacation (YYYY-MM-DD)")
    end_date: str = Field(description="The end date of the vacation (YYYY-MM-DD)")
    request_type: str = Field(description="The type of request, e.g., 'vacation'")

class HRAgent:
    def __init__(self, google_api_key: str, openai_api_key: str, vacations_file: str, tickets_file: str):
        """Initialize the HR Agent with structured chat format"""
        self.google_api_key = google_api_key
        self.openai_api_key = openai_api_key
        
        # Initialize Tools
        self.rag_tool = RAGTool(
            google_api_key=self.google_api_key,
            openai_api_key=self.openai_api_key
        )
        
        self.vacation_tool = VacationTool(vacations_file)
        self.ticket_tool = TicketTool(tickets_file)
        self.support_ticket_tool = SupportTicketTool(tickets_file)

        # Initialize Gemini LLM
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash-exp",
            temperature=0.3,
            google_api_key=self.google_api_key
        )

        # Define tools with improved descriptions
        self.tools = [
            StructuredTool.from_function(
                name="PolicyQuery",
                func=self.rag_tool.query,
                description="ÙŠØ³ØªØ®Ø¯Ù… Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù† Ø£Ø³Ø¦Ù„Ø© Ø³ÙŠØ§Ø³Ø§Øª Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø¨Ø´Ø±ÙŠØ©. Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª: Ø³Ø¤Ø§Ù„ (Ù†Øµ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)"
            ),
            StructuredTool.from_function(
                name="CheckVacationBalance",
                func=self.vacation_tool.check_balance,
                description="ÙŠØªØ­Ù‚Ù‚ Ù…Ù† Ø±ØµÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø²Ø§Øª. Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª: employee_id (Ù†Øµ)"
            ),
            StructuredTool.from_function(
                name="CreateVacationRequest",
                func=self.ticket_tool.create_ticket,
                description="""ÙŠÙ†Ø´Ø¦ Ø·Ù„Ø¨ Ø¥Ø¬Ø§Ø²Ø©. Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª: Ù‚Ø§Ù…ÙˆØ³ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰:
                'employee_id': Ù†Øµ
                'start_date': YYYY-MM-DD
                'end_date': YYYY-MM-DD
                'request_type': 'Ø³Ù†ÙˆÙŠØ©'/'Ù…Ø±Ø¶ÙŠØ©'/'Ø·Ø§Ø±Ø¦Ø©'"""
            ),
            StructuredTool.from_function(
                name="CreateSupportTicket",
                func=self.support_ticket_tool.create_ticket,
                description="""ÙŠÙ†Ø´Ø¦ ØªØ°ÙƒØ±Ø© Ø¯Ø¹Ù… (Ø¨Ø¹Ø¯ Ù…ÙˆØ§ÙÙ‚Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…). Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª: Ù‚Ø§Ù…ÙˆØ³ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰:
                'employee_id': Ù†Øµ
                'summary': Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©
                'description': ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©"""
            )
        ]

        # Create structured chat prompt
        system_template = """Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø¨Ø´Ø±ÙŠØ©. Ù„Ø¯ÙŠÙƒ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:

{tools}

Ø§Ø³ØªØ®Ø¯Ù… ØªÙ†Ø³ÙŠÙ‚ JSON Ù„Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¯Ø§Ø© Ù…Ù† Ø®Ù„Ø§Ù„ ØªÙˆÙÙŠØ± Ù…ÙØªØ§Ø­ action (Ø§Ø³Ù… Ø§Ù„Ø£Ø¯Ø§Ø©) ÙˆÙ…ÙØªØ§Ø­ action_input (Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø©).

Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ØµØ§Ù„Ø­Ø© Ù„Ù€ "action": "Final Answer" Ø£Ùˆ {tool_names}

Ù‚Ø¯Ù… Ø¥Ø¬Ø±Ø§Ø¡Ù‹ ÙˆØ§Ø­Ø¯Ø§Ù‹ ÙÙ‚Ø· Ù„ÙƒÙ„ JSON_BLOB ÙƒÙ…Ø§ ÙŠÙ„ÙŠ:

```
{{
  "action": $TOOL_NAME,
  "action_input": $INPUT
}}
```

ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù…Ù‡Ù…Ø©:
1. ØªØ­Ù‚Ù‚ Ù…Ù† Ø±ØµÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø²Ø© Ù‚Ø¨Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø·Ù„Ø¨ Ø¥Ø¬Ø§Ø²Ø©
2. Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ù…ÙˆØ§ÙÙ‚Ø© ØµØ±ÙŠØ­Ø© Ù‚Ø¨Ù„ Ø¥Ù†Ø´Ø§Ø¡ ØªØ°ÙƒØ±Ø© Ø¯Ø¹Ù…
3. ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ù‚Ø¨Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø£ÙŠ ØªØ°ÙƒØ±Ø©
4. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø¹Ù†Ø¯ ØªÙˆÙØ±Ù‡Ø§

ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØªØ°Ø§ÙƒØ±:
- ØªØ°Ø§ÙƒØ± Ø§Ù„Ø¯Ø¹Ù…: ST-XXXX
- ØªØ°Ø§ÙƒØ± Ø§Ù„Ø¥Ø¬Ø§Ø²Ø©: VT-XXXX"""

        human_template = """{input}

{agent_scratchpad}"""

        self.prompt = ChatPromptTemplate.from_messages([
            ("system", system_template),
            MessagesPlaceholder(variable_name="chat_history", optional=True),
            ("human", human_template),
        ])

        # Initialize structured chat agent
        agent = create_structured_chat_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=self.prompt,
            stop_sequence=True
        )

        # Create agent executor
        self.agent_executor = AgentExecutor(
            agent=agent,
            tools=self.tools,
            verbose=True,
            handle_parsing_errors=True,
            max_iterations=5
        )

        self.active_docs = []

    def process_query(self, message: str, employee_id: Optional[str] = None, metadata: Optional[Dict] = None) -> str:
        """Process user query with structured chat format and history"""
        try:
            # Load chat history
            history = []
            formatted_history = []
            if employee_id:
                history_file = f'data/chat_history_{employee_id}.json'
                try:
                    with open(history_file, 'r', encoding='utf-8') as f:
                        history = json.load(f)
                        formatted_history = [
                            HumanMessage(content=msg["content"]) if msg["type"] == "user"
                            else AIMessage(content=msg["content"])
                            for msg in history
                        ]
                except FileNotFoundError:
                    pass

            # Handle vacation-related queries without employee_id
            if not employee_id and any(
                    keyword in message.lower() for keyword in ["Ø±ØµÙŠØ¯ Ø§Ø¬Ø§Ø²ØªÙŠ", "ÙƒÙ… ÙŠÙˆÙ… Ø¨Ø§Ù‚ÙŠ"]
            ):
                return "ÙŠØ±Ø¬Ù‰ ØªÙ‚Ø¯ÙŠÙ… Ø±Ù‚Ù… Ø§Ù„Ù…ÙˆØ¸Ù Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©"

            # Prepare context for the agent
            context = {
                "input": f"[Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {employee_id or 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ'}]\n{message}",
                "chat_history": formatted_history,
                "metadata": metadata or {}
            }

            # Get agent response
            result = self.agent_executor.invoke(context)

            # Save chat history
            if employee_id:
                new_history = history + [
                    {"type": "user", "content": message},
                    {"type": "bot", "content": result['output']}
                ]
                with open(history_file, 'w', encoding='utf-8') as f:
                    json.dump(new_history, f, ensure_ascii=False, indent=2)

            return result.get('output', "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©. ÙŠØ±Ø¬Ù‰ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©")

        except Exception as e:
            print(f"Error processing query: {str(e)}")
            return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰."

    def add_document(self, filepath: str) -> bool:
        """Add a new document to the RAG system"""
        try:
            result = self.rag_tool.add_document(filepath)
            if result:
                self.active_docs.append(filepath)
            return result
        except Exception as e:
            print(f"Error adding document: {str(e)}")
            return False
        
    def get_all_tickets(self):

        """Reads and returns all tickets from the CSV file, handling NaN values."""

        try:

            df = pd.read_csv(self.ticket_tool.tickets_file)



            # Replace NaN values with appropriate defaults

            df = df.fillna({'description': '', 'manager_id': '', 'response_date': '', 'updated_at': ''})



            tickets = df.to_dict('records')

            return tickets

        except Exception as e:

            print(f"Error reading tickets: {str(e)}")

            return []

    def update_active_documents(self, document_list: List[str]) -> bool:
        """Update the list of active documents"""
        try:
            success = self.rag_tool.update_active_documents(document_list)
            if success:
                self.active_docs = document_list
            return success
        except Exception as e:
            print(f"Error updating active documents: {str(e)}")
            return False

    def get_vacation_balance(self, employee_id: str) -> Dict:
        """Get vacation balance for an employee"""
        try:
            return self.vacation_tool.check_balance(employee_id)
        except Exception as e:
            print(f"Error getting vacation balance: {str(e)}")
            return {"error": "Could not retrieve vacation balance"}

    def create_vacation_ticket(self, employee_id: str, start_date: str, end_date: str, request_type: str, notes: str = "") -> Dict:
        """Create a new vacation request ticket"""
        try:
            return self.ticket_tool.create_ticket(employee_id, start_date, end_date, request_type, notes)
        except Exception as e:
            print(f"Error creating vacation ticket: {str(e)}")
            return {"error": "Could not create vacation ticket"}

    def get_employee_tickets(self, employee_id: str) -> Dict:
        """Get all tickets for an employee"""
        try:
            return self.ticket_tool.get_employee_tickets(employee_id)
        except Exception as e:
            print(f"Error getting employee tickets: {str(e)}")
            return {"error": "Could not retrieve tickets"}

def main():
    """Test the improved HR Agent"""
    load_dotenv()
    google_api_key = os.getenv('GOOGLE_API_KEY')
    openai_api_key = os.getenv('OPENAI_API_KEY')

    try:
        # Initialize agent
        agent = HRAgent(
            google_api_key=google_api_key,
            openai_api_key=openai_api_key,
            vacations_file='data/vacations.csv',
            tickets_file='data/tickets.csv'
        )

        # Test conversation flows
        test_conversations = [
            # Vacation request flow
            [
                ("Ø§Ø±ÙŠØ¯ Ø§Ù† Ø§Ù‚Ø¯Ù… Ø·Ù„Ø¨ Ø§Ø¬Ø§Ø²Ø©", "1001"),
                ("ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨Ø¯Ø¡ 2025-07-01", "1001"),
                ("ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ 2025-07-10 ÙˆÙ†ÙˆØ¹Ù‡Ø§ Ø³Ù†ÙˆÙŠØ©", "1001"),
                ("Ù†Ø¹Ù…", "1001")
            ],
            # Support ticket flow
            [
                ("Ù…Ø§ Ù‡ÙŠ Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù† Ø¨Ø¹Ø¯ØŸ", "1001"),
                ("Ù„Ø§ Ù‡Ø°Ø§ ØºÙŠØ± Ù…ÙÙŠØ¯", "1001"),
                ("Ù†Ø¹Ù… Ø£Ø±ÙŠØ¯ Ø§Ù„ØªØ­Ø¯Ø« Ù…Ø¹ Ù…ÙˆØ¸Ù", "1001")
            ]
        ]

        for conversation in test_conversations:
            print("\nTesting new conversation flow:")
            for message, emp_id in conversation:
                print(f"\nUser ({emp_id}): {message}")
                response = agent.process_query(message, employee_id=emp_id)
                print(f"Agent: {response}")

    except Exception as e:
        print(f"Test failed: {str(e)}")

if __name__ == "__main__":
    main()
</file>

<file path="app.py">
from flask import Flask, request, jsonify, send_file, send_from_directory
from flask_cors import CORS
from werkzeug.utils import secure_filename
import os
from datetime import datetime
from agent import HRAgent
import pandas as pd
from dotenv import load_dotenv
from datetime import datetime
import json
from tools.support_ticket_tool import SupportTicketTool
import shutil



# Load environment variables
load_dotenv()
app = Flask('__name__', static_folder='static', static_url_path='')
#app = Flask(__name__)
CORS(app)
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Configurationag
UPLOAD_FOLDER = 'data/documents'
ALLOWED_EXTENSIONS = {'pdf', 'docx', 'doc', 'txt'}
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER

# Ensure upload directory exists
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# Initialize HR Agent
agent = HRAgent(
    google_api_key=os.getenv('GOOGLE_API_KEY'),
    openai_api_key=os.getenv('OPENAI_API_KEY'),
    vacations_file='data/vacations.csv',
    tickets_file='data/tickets.csv'
)

@app.route('/')
def serve():
    return send_from_directory(app.static_folder, 'index.html')

@app.errorhandler(404)
def not_found(e):
    return send_from_directory(app.static_folder, "index.html")

           
@app.route('/api/auth/login', methods=['POST'])
def login():
    data = request.json
    username = data.get('username')
    password = data.get('password')
    
    # Simple mock users for MVP
    mock_users = {
    'user1': {
        'id': '1001',
        'name': 'Ù…Ø­Ù…Ø¯ Ø§Ø­Ù…Ø¯',
        'role': 'employee',
        'employee_id': '1001'
    },
    'admin': {
        'id': '9001',
        'name': 'Admin User',
        'role': 'admin',
        'employee_id': '9001'
    }
                }
    
    if username in mock_users:
        return jsonify({
            'status': 'success',
            'user': mock_users[username]
        })
    else:
        return jsonify({
            'status': 'error',
            'message': 'Invalid credentials'
        }), 401

@app.route('/api/chat/history/<employee_id>', methods=['GET'])
def get_chat_history(employee_id):
    try:
        # Try to load existing history
        history_file = f'data/chat_history_{employee_id}.json'
        try:
            with open(history_file, 'r', encoding='utf-8') as f:
                history = json.load(f)
        except FileNotFoundError:
            history = []
        
        return jsonify({
            'status': 'success',
            'history': history
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500



@app.route('/api/chat', methods=['POST'])
def chat():
    try:
        data = request.json
        message = data.get('message', '').strip()
        employee_id = data.get('type')
        
        if not message:
            return jsonify({'error': 'Message is required'}), 400
        
        # Process message through agent
        response = agent.process_query(message, employee_id)
        
        # Save to chat history if employee_id is provided
        if employee_id:
            history_file = f'data/chat_history_{employee_id}.json'
            try:
                with open(history_file, 'r', encoding='utf-8') as f:
                    history = json.load(f)
            except FileNotFoundError:
                history = []
            
            # Add new messages
            timestamp = datetime.now().isoformat()
            history.append({
                'id': str(len(history) + 1),
                'content': message,
                'type': 'user',
                'timestamp': timestamp,
                'status': 'sent'
            })
            history.append({
                'id': str(len(history) + 2),
                'content': response,
                'type': 'bot',
                'timestamp': timestamp,
                'status': 'sent'
            })
            
            # Save updated history
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(history, f, ensure_ascii=False, indent=2)
        
        return jsonify({
            'response': response,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"Error in chat endpoint: {str(e)}")
        return jsonify({
            'error': 'Internal server error',
            'message': str(e)
        }), 500

def allowed_file(filename):
    """Check if file extension is allowed"""
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

@app.route('/api/admin/upload', methods=['POST'])
def upload_document():
    """Handle document uploads"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'Ù„Ù… ÙŠØªÙ… ØªÙˆÙÙŠØ± Ù…Ù„Ù', 'message': 'Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø±Ø³Ø§Ù„ Ù…Ù„Ù ÙƒØ¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø·Ù„Ø¨'}), 400

        file = request.files['file']
        file_type = request.form.get('fileType')  # Get file type from form data

        if file.filename == '':
            return jsonify({'error': 'Ù„Ù… ÙŠØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ù…Ù„Ù', 'message': 'Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø± Ù…Ù„Ù Ù„Ù„Ø±ÙØ¹'}), 400

        if not allowed_file(file.filename):
            return jsonify({'error': 'Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡', 'message': 'Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡Ø§ Ù‡ÙŠ: PDFØŒ DOCXØŒ DOCØŒ TXT'}), 400

        # Check file size
        file.seek(0, os.SEEK_END)  # Go to the end of the file
        file_length = file.tell()  # Get the file size
        file.seek(0)  # Rewind to the beginning
        if file_length > app.config['MAX_CONTENT_LENGTH']:
            return jsonify({'error': 'Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù ÙƒØ¨ÙŠØ± Ø¬Ø¯Ø§Ù‹', 'message': f'Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù Ù‡Ùˆ {app.config["MAX_CONTENT_LENGTH"] / (1024 * 1024)} Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª'}), 400

        filename = secure_filename(file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)

        # Save the file
        file.save(filepath)
        
        # Get the timestamp when the file was uploaded
        uploaded_at = datetime.now().isoformat()

        # Process the document with RAG system
        agent.add_document(filepath)

        # Prepare document metadata
        document_metadata = {
            'id': filename,  # Using filename as a temporary ID; you might want to generate a unique ID
            'title': filename,
            'fileType': file_type,  # Use the file type from form data
            'size': file_length,
            'uploadedBy': 'user_id',  # Replace with actual user ID if you have authentication
            'uploadedAt': uploaded_at,
            'status': 'processing',  # You can update this status after RAG processing
            'lastModified': uploaded_at
        }

        return jsonify({
            'message': 'ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø¨Ù†Ø¬Ø§Ø­',
            'filename': filename,
            'document': document_metadata,
            'status':'success'
        }), 200

    except Exception as e:
        print(f"Error in upload endpoint: {str(e)}")
        return jsonify({
            'error': 'Internal server error',
            'message': str(e)
        }), 500

@app.route('/api/admin/documents', methods=['GET'])
def list_documents():
    """List all available documents"""
    try:
        files = []
        for filename in os.listdir(app.config['UPLOAD_FOLDER']):
            if allowed_file(filename):
                filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
                files.append({
                    'name': filename,
                    'size': os.path.getsize(filepath),
                    'uploaded': datetime.fromtimestamp(
                        os.path.getctime(filepath)
                    ).isoformat()
                })
                
        return jsonify({'documents': files})
        
    except Exception as e:
        print(f"Error listing documents: {str(e)}")
        return jsonify({
            'error': 'Internal server error',
            'message': str(e)
        }), 500

@app.route('/api/admin/documents', methods=['POST'])
def update_active_documents():
    """Update which documents are active in the RAG system"""
    try:
        data = request.json
        document_list = data.get('documents', [])
        
        # Update active documents in the agent
        agent.update_active_documents(document_list)
        
        return jsonify({
            'message': 'Active documents updated successfully',
            'active_documents': document_list
        })
        
    except Exception as e:
        print(f"Error updating active documents: {str(e)}")
        return jsonify({
            'error': 'Internal server error',
            'message': str(e)
        }), 500

@app.route('/api/employee/vacation-balance/<employee_id>', methods=['GET'])
def get_vacation_balance(employee_id):
    """Get vacation balance for an employee"""
    try:
        balance = agent.get_vacation_balance(employee_id)
        return jsonify(balance)
        
    except Exception as e:
        print(f"Error getting vacation balance: {str(e)}")
        return jsonify({
            'error': 'Internal server error',
            'message': str(e)
        }), 500
        
@app.route('/api/employee/vacation-requests/<employee_id>', methods=['GET'])
def get_vacation_requests(employee_id):
    """Get list of vacation requests for an employee"""
    try:
        requests = agent.get_employee_tickets(employee_id)  # Assuming you have a method like this in your agent
        if requests["status"] == "success":
            return jsonify({
                'status': 'success',
                'data': requests["tickets"] # Assuming your agent returns data in this format
            })
        else:
            return jsonify({'error': requests["error"], 'status': 'error'}), 500

    except Exception as e:
        print(f"Error getting vacation requests: {str(e)}")
        return jsonify({
            'error': 'Internal server error',
            'message': str(e)
        }), 500

@app.route('/api/employee/vacation-request', methods=['POST'])
def submit_vacation_request():
    """Submit a new vacation request"""
    try:
        data = request.json
        employee_id = data.get('type')
        start_date = data.get('start_date')
        end_date = data.get('end_date')
        request_type = data.get('request_type')
        notes = data.get('notes', '')

        if not all([employee_id, start_date, end_date, request_type]):
            return jsonify({'error': 'Missing required fields'}), 400

        ticket = agent.create_vacation_ticket(
            employee_id=employee_id,
            start_date=start_date,
            end_date=end_date,
            request_type=request_type,
            notes=notes
        )
        return jsonify(ticket)

    except Exception as e:
        print(f"Error submitting vacation request: {str(e)}")
        return jsonify({
            'error': 'Internal server error',
            'message': str(e)
        }), 500
        
@app.route('/api/admin/tickets', methods=['GET'])
def admin_get_tickets():
    """Endpoint to retrieve all tickets (for admin users)."""
    try:
        tickets = agent.get_all_tickets()
        print("Raw tickets from CSV:", tickets)
        
        # Clean and process the tickets data
        processed_tickets = []
        for ticket in tickets:
            # Convert 'nan' and NaN values to None/null
            processed_ticket = {
                'ticket_id': str(ticket.get('ticket_id', '')),
                'employee_id': str(ticket.get('employee_id', '')),
                'request_type': str(ticket.get('request_type')) if ticket.get('request_type') and ticket.get('request_type') != 'nan' else None,
                'start_date': str(ticket.get('start_date')) if ticket.get('start_date') and ticket.get('start_date') != 'nan' else None,
                'end_date': str(ticket.get('end_date')) if ticket.get('end_date') and ticket.get('end_date') != 'nan' else None,
                'days_count': float(ticket.get('days_count')) if ticket.get('days_count') and not pd.isna(ticket.get('days_count')) else None,
                'status': str(ticket.get('status', 'pending')),
                'manager_id': str(ticket.get('manager_id')) if ticket.get('manager_id') and ticket.get('manager_id') != 'nan' else None,
                'request_date': str(ticket.get('request_date')) if ticket.get('request_date') and ticket.get('request_date') != 'nan' else None,
                'response_date': str(ticket.get('response_date')) if ticket.get('response_date') and ticket.get('response_date') != 'nan' else None,
                'notes': str(ticket.get('notes')) if ticket.get('notes') and ticket.get('notes') != 'nan' else None,
                'summary': str(ticket.get('summary')) if ticket.get('summary') and ticket.get('summary') != 'nan' else None,
                'description': str(ticket.get('description')) if ticket.get('description') and ticket.get('description') != 'nan' else None,
                'created_at': str(ticket.get('created_at')) if ticket.get('created_at') and ticket.get('created_at') != 'nan' else None,
                'updated_at': str(ticket.get('updated_at')) if ticket.get('updated_at') and ticket.get('updated_at') != 'nan' else None
            }
            processed_tickets.append(processed_ticket)

        return jsonify({
            'tickets': processed_tickets,
            'status': 'success'
        })

    except Exception as e:
        print(f"Error getting tickets: {str(e)}")
        return jsonify({
            'error': 'Could not retrieve tickets',
            'status': 'error'
        }), 500
    
@app.route('/api/admin/documents/<document_id>', methods=['DELETE'])
def delete_document(document_id):
    """Endpoint to delete a document and its associated ChromaDB collection."""
    try:
        # In a real app, you'd verify the user's role here (admin).

        # Use the document_id (filename) to delete the document and collection
        if agent.delete_document_and_collection(document_id):
            return jsonify({'message': 'Document and associated collection deleted', 'status': 'success'})
        else:
            return jsonify({'error': 'Could not delete document or collection', 'status': 'error'}), 500

    except Exception as e:
        print(f"Error deleting document: {str(e)}")
        return jsonify({'error': 'Could not delete document', 'status': 'error'}), 500

if __name__ == '__main__':
    # Load initial documents if any exist
    try:
        for filename in os.listdir(app.config['UPLOAD_FOLDER']):
            if allowed_file(filename):
                print(f"Processing file: {filename}")
                filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
                agent.add_document(filepath)
        print("Initial documents loaded")
    except Exception as e:
        print(f"Error loading initial documents: {str(e)}")
    
    #app.run( port=5000)
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=True)
</file>

<file path="config.py">
# config.py

import os
from pathlib import Path
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# API Keys
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Base Paths
BASE_DIR = Path(__file__).parent
DATA_DIR = BASE_DIR / "data"

# Document paths
DOCUMENTS_DIR = DATA_DIR / "documents"
CHROMA_DIR = DATA_DIR / "chroma_db"
DOCUMENT_MAPPING_FILE = DATA_DIR / "document_mapping.csv"

# CSV file paths
VACATIONS_FILE = DATA_DIR / "vacations.csv"
TICKETS_FILE = DATA_DIR / "tickets.csv"

# Ensure directories exist
DOCUMENTS_DIR.mkdir(parents=True, exist_ok=True)
CHROMA_DIR.mkdir(parents=True, exist_ok=True)

# RAG Configuration
RAG_CONFIG = {
    "chunk_size": 500,
    "chunk_overlap": 50,
    "model_name": "gemini-pro",
    "temperature": 0.3
}

# Default admin credentials (for demo purposes)
DEFAULT_ADMIN = {
    "username": "admin",
    "password": "admin123"  # In production, use proper authentication
}

# File upload settings
ALLOWED_EXTENSIONS = {'pdf', 'docx', 'doc', 'txt'}
MAX_CONTENT_LENGTH = 16 * 1024 * 1024  # 16MB max file size
</file>

<file path="hardcode.py">
from flask import Flask, request, jsonify
from flask_cors import CORS
import time

app = Flask(__name__)
CORS(app)

# Store conversation state
conversation_states = {}

# Predefined responses
RESPONSES = {
    "remote_work_policy": """ğŸ  Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù† Ø¨Ø¹Ø¯ ÙÙŠ Ø´Ø±ÙƒØªÙ†Ø§:

â€¢ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù† Ø¨Ø¹Ø¯ Ù„Ù…Ø¯Ø© 14 ÙŠÙˆÙ… ÙÙŠ Ø§Ù„Ø³Ù†Ø©
â€¢ ÙŠØ¬Ø¨ Ø¥Ø®Ø·Ø§Ø± Ù…Ø¯ÙŠØ±Ùƒ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù‚Ø¨Ù„ 3 Ø£ÙŠØ§Ù… Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„
â€¢ ÙŠØªØ·Ù„Ø¨ Ø§Ù„Ø­Ø¶ÙˆØ± Ù„Ù„Ù…ÙƒØªØ¨ ÙÙŠ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø©
â€¢ ÙŠØ¬Ø¨ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ù…Ø¹ØªØ§Ø¯Ø©
â€¢ ØªÙˆÙÙŠØ± ØªÙ‚Ø±ÙŠØ± Ø£Ø³Ø¨ÙˆØ¹ÙŠ Ø¹Ù† Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ù†Ø¬Ø²Ø©

Ù‡Ù„ Ù„Ø¯ÙŠÙƒ Ø£ÙŠ Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª Ø£Ø®Ø±Ù‰ØŸ ğŸ’¼""",
    
    "paid_leave_question": """âœ… Ù†Ø¹Ù…ØŒ ÙØªØ±Ø© Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù† Ø¨Ø¹Ø¯ Ù‡ÙŠ Ø¥Ø¬Ø§Ø²Ø© Ù…Ø¯ÙÙˆØ¹Ø© Ù„Ù…Ø¯Ø© 14 ÙŠÙˆÙ….

Ù‡Ù„ ØªØ±ÙŠØ¯ ØªÙ‚Ø¯ÙŠÙ… Ø·Ù„Ø¨ Ù„Ù„Ø¹Ù…Ù„ Ø¹Ù† Ø¨Ø¹Ø¯ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¯Ø©ØŸ ğŸ“""",
    
    "leave_confirmation": """ğŸ‰ ØªÙ… ØªÙ‚Ø¯ÙŠÙ… Ø·Ù„Ø¨ Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù† Ø¨Ø¹Ø¯ Ø¨Ù†Ø¬Ø§Ø­!

â€¢ Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨: #WFH-2024-001
â€¢ Ø§Ù„Ù…Ø¯Ø©: 14 ÙŠÙˆÙ…
â€¢ Ø§Ù„Ø­Ø§Ù„Ø©: Ø¨Ø§Ù†ØªØ¸Ø§Ø± Ù…ÙˆØ§ÙÙ‚Ø© Ø§Ù„Ù…Ø¯ÙŠØ±

Ø³ÙŠØªÙ… Ø¥Ø´Ø¹Ø§Ø±Ùƒ Ø¹Ø¨Ø± Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ ÙÙˆØ± Ù…Ø±Ø§Ø¬Ø¹Ø© Ø·Ù„Ø¨Ùƒ ğŸ“§"""
}

@app.route('/api/chat', methods=['POST'])
def chat():
    data = request.json
    message = data.get('message', '').strip()
    conversation_id = data.get('conversation_id', 'default')
    
    # Simulate processing time
    time.sleep(1)
    
    # Get current state
    current_state = conversation_states.get(conversation_id, 'initial')
    
    # Process message based on current state and content
    if "Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù† Ø¨Ø¹Ø¯" in message:
        conversation_states[conversation_id] = 'asked_policy'
        return jsonify({
            "response": RESPONSES["remote_work_policy"],
            "conversation_id": conversation_id
        })
    
    elif "Ø§Ø¬Ø§Ø²Ø© Ù…Ø¯ÙÙˆØ¹Ø©" in message and current_state == 'asked_policy':
        conversation_states[conversation_id] = 'asked_paid'
        return jsonify({
            "response": RESPONSES["paid_leave_question"],
            "conversation_id": conversation_id
        })
    
    elif any(word in message.lower() for word in ["Ù†Ø¹Ù…", "Ø§Ø¬Ù„", "Ù…ÙˆØ§ÙÙ‚"]) and current_state == 'asked_paid':
        conversation_states[conversation_id] = 'confirmed'
        return jsonify({
            "response": RESPONSES["leave_confirmation"],
            "conversation_id": conversation_id
        })
    
    # Default response
    return jsonify({
        "response": "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£ÙÙ‡Ù… Ø³Ø¤Ø§Ù„Ùƒ. Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØªÙ‡ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø£Ø®Ø±Ù‰ØŸ ğŸ¤”",
        "conversation_id": conversation_id
    })

if __name__ == '__main__':
    app.run(debug=True, port=5000)
</file>

<file path="rag_system.py">
# rag_system.py

import os
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime
import google.generativeai as genai
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings
import logging
from pathlib import Path
from langchain.document_loaders import PyPDFLoader
from langchain_openai import OpenAIEmbeddings , ChatOpenAI  # Import OpenAIEmbeddings



# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class DocumentMetadata:
    """Metadata for processed documents"""
    title: str
    file_type: str
    created_date: str
    collection_id: str
    page_count: int
    status: str  # 'processing', 'active', 'error'
    error_message: Optional[str] = None
    last_updated: str = datetime.now().isoformat()

@dataclass
class ProcessedDocument:
    """Processed document information"""
    chunks: List[str]
    metadata: DocumentMetadata
    collection_path: str
    total_chunks: int
    embedding_status: str  # 'pending', 'completed', 'error'

class DocumentProcessor:
    """Handles document processing and embedding"""
    
    def __init__(self, google_api_key: str, openai_api_key: str, base_path: str = "./data"):
        """Initialize the document processor."""
        self.google_api_key = google_api_key
        self.openai_api_key = openai_api_key
        self.base_path = base_path
        
        # Initialize OpenAI embeddings
        self.embeddings = OpenAIEmbeddings(
            api_key=self.openai_api_key,
            model="text-embedding-ada-002"
        )
        
        # Configure text splitter for Arabic and English
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=2048,
            chunk_overlap=200,
            length_function=len,
            separators=["\n\n", "\n", ".", "!", "?", "ØŸ", "ØŒ", " "]
        )
        
        # Ensure directory structure exists
        self.docs_path = Path(base_path) / "documents"
        self.chroma_path = Path(base_path) / "chroma_db"
        self.docs_path.mkdir(parents=True, exist_ok=True)
        self.chroma_path.mkdir(parents=True, exist_ok=True)

    def process_document(self, file_path: str) -> ProcessedDocument:
        """
        Process a document and prepare it for embedding.
        
        Args:
            file_path: Path to the document file
            
        Returns:
            ProcessedDocument object containing chunks and metadata
        """
        try:
            logger.info(f"Starting document processing: {file_path}")
            
            # Extract text based on file type
            text = self._extract_text(file_path)
            
            # Create document metadata
            metadata = self._create_metadata(file_path)
            
            # Split text into chunks
            chunks = self.text_splitter.split_text(text)
            
            # Create collection path
            collection_path = self.chroma_path / metadata.collection_id
            
            # Create processed document
            processed_doc = ProcessedDocument(
                chunks=chunks,
                metadata=metadata,
                collection_path=str(collection_path),
                total_chunks=len(chunks),
                embedding_status='pending'
            )
            
            logger.info(f"Document processed successfully: {metadata.collection_id}")
            return processed_doc
            
        except Exception as e:
            error_msg = f"Error processing document: {str(e)}"
            logger.error(error_msg)
            raise Exception(error_msg)

    def _extract_text(self, file_path: str) -> str:
        """Extract text from different document types."""
        file_type = Path(file_path).suffix.lower()
        
        try:
            if file_type == '.pdf':
                return self._extract_pdf_text(file_path)
            elif file_type in ['.docx', '.doc']:
                return self._extract_word_text(file_path)
            elif file_type == '.txt':
                return self._extract_txt_text(file_path)
            else:
                raise ValueError(f"Unsupported file type: {file_type}")
                
        except Exception as e:
            raise Exception(f"Error extracting text: {str(e)}")

    def _extract_pdf_text(self, file_path: str) -> str:
        """Extract text from PDF files."""
        try:
            from langchain_community.document_loaders import PyPDFLoader
            loader = PyPDFLoader(file_path) # or parser="pypdfium"
            documents = loader.load()
            text = "\n\n".join([doc.page_content for doc in documents])
            return text
                
        except Exception as e:
            raise Exception(f"Error extracting PDF text: {str(e)}")

    def _extract_word_text(self, file_path: str) -> str:
        """Extract text from Word documents."""
        try:
            from docx import Document
            
            doc = Document(file_path)
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            return text
            
        except Exception as e:
            raise Exception(f"Error extracting Word text: {str(e)}")

    def _extract_txt_text(self, file_path: str) -> str:
        """Extract text from txt files."""
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                return file.read()
        except Exception as e:
            raise Exception(f"Error extracting text file text: {str(e)}")

    def _create_metadata(self, file_path: str) -> DocumentMetadata:
        """Create metadata for a document."""
        file_path = Path(file_path)
        creation_time = datetime.fromtimestamp(file_path.stat().st_ctime)
        
        return DocumentMetadata(
            title=file_path.name,
            file_type=file_path.suffix[1:],  # Remove the dot
            created_date=creation_time.isoformat(),
            collection_id=f"doc_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            page_count=0,  # Will be updated based on document type
            status='processing'
        )

    def create_embeddings(self, processed_doc: ProcessedDocument) -> Chroma:
        """Create embeddings for processed document chunks."""
        try:
            logger.info(f"Creating embeddings for document: {processed_doc.metadata.collection_id}")
            
            # Prepare metadata for each chunk
            chunk_metadata = []
            for i, chunk in enumerate(processed_doc.chunks):
                chunk_metadata.append({
                    "chunk_id": str(i),
                    "document_title": processed_doc.metadata.title,
                    "collection_id": processed_doc.metadata.collection_id
                })
            
            # Create and persist vector store
            vectorstore = Chroma.from_texts(
                texts=processed_doc.chunks,
                metadatas=chunk_metadata,
                embedding=self.embeddings,
                persist_directory=processed_doc.collection_path
            )
            
        
            
            logger.info(f"Embeddings created successfully: {processed_doc.metadata.collection_id}")
            return vectorstore
            
        except Exception as e:
            error_msg = f"Error creating embeddings: {str(e)}"
            logger.error(error_msg)
            raise Exception(error_msg)
        
        
# Continuing rag_system.py

class HRRAGSystem:
    """Main RAG system for HR document queries"""
    def __init__(self, google_api_key: str, openai_api_key: str, base_path: str = "./data"):
        """Initialize the HR RAG system."""
        self.google_api_key = google_api_key
        self.openai_api_key = openai_api_key
        self.base_path = Path(base_path)
        
        # Initialize document processor with both API keys
        self.doc_processor = DocumentProcessor(google_api_key, openai_api_key, base_path)
        
        # Initialize Gemini LLM
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash-exp",
            temperature=0.3,
            google_api_key=self.google_api_key
        )
        
        # Keep track of active collections
        self.active_collections: Dict[str, Chroma] = {}
        
        # Initialize from existing collections if any
        self._load_existing_collections()

    def _load_existing_collections(self):
        """Load existing collections from chroma_db directory."""
        logger.info("Loading existing collections...")
        try:
            chroma_path = self.base_path / "chroma_db"
            if chroma_path.exists():
                for collection_dir in chroma_path.iterdir():
                    if collection_dir.is_dir():
                        try:
                            vectorstore = Chroma(
                                persist_directory=str(collection_dir),
                                embedding_function=self.doc_processor.embeddings
                            )
                            self.active_collections[collection_dir.name] = vectorstore
                            # Log the number of documents in the collection
                            num_docs = vectorstore._collection.count()
                            logger.info(f"Loaded collection: {collection_dir.name} with {num_docs} documents")
                        except Exception as e:
                            logger.error(f"Error loading collection {collection_dir.name}: {str(e)}")

        except Exception as e:
            logger.error(f"Error loading existing collections: {str(e)}")


    def process_document(self, file_path: str) -> str:
        """
        Process a new document and add it to the RAG system.
        
        Args:
            file_path: Path to the document file
            
        Returns:
            collection_id: ID of the created collection
        """
        try:
            # Process document
            processed_doc = self.doc_processor.process_document(file_path)
            
            # Create embeddings
            logger.info(
                f"Creating embeddings for document: {processed_doc.metadata.collection_id}"
            )
            vectorstore = self.doc_processor.create_embeddings(processed_doc)
            # Log the number of chunks embedded:
            logger.info(f"Created embeddings for {len(processed_doc.chunks)} chunks.")

            # Add to active collections
            self.active_collections[
                processed_doc.metadata.collection_id
            ] = vectorstore

            # Update metadata status
            processed_doc.metadata.status = "active"
            processed_doc.embedding_status = "completed"

            # log the active collections
            logger.info(
                f"Active collections: {', '.join(self.active_collections.keys())}"
            )
            
            return processed_doc.metadata.collection_id
            
        except Exception as e:
            logger.error(f"Error processing document: {str(e)}")
            raise

    def query(self, question: str, collection_ids: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        Query the RAG system with a question.
        
        Args:
            question: The question to ask
            collection_ids: Optional list of specific collection IDs to query
            
        Returns:
            Dict containing answer and source documents
        """
        try:
            # If no specific collections provided, use all active ones
            collections_to_query = []
            if collection_ids:
                for cid in collection_ids:
                    if cid in self.active_collections:
                        collections_to_query.append(self.active_collections[cid])
            else:
                collections_to_query = list(self.active_collections.values())

            if not collections_to_query:
                return {
                    "answer": "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ù…ØªØ§Ø­Ø© Ù„Ù„Ø¨Ø­Ø«.",
                    "source_documents": []
                }

            # Combine results from all collections
            all_docs = []
            for vectorstore in collections_to_query:
                docs = vectorstore.similarity_search(question, k=10)
                all_docs.extend(docs)

            # Sort by relevance (assumed from order) and take top results
            context = "\n".join(doc.page_content for doc in all_docs[:15])

            # Generate response using LLM
            prompt = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø¨Ø´Ø±ÙŠØ©. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„.
            Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙÙŠ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªÙˆÙØ±ØŒ Ù‚Ù„ Ø°Ù„Ùƒ Ø¨ØµØ±Ø§Ø­Ø©.

            Ø§Ù„Ø³Ø¤Ø§Ù„: {question}

            Ø§Ù„Ø³ÙŠØ§Ù‚:
            {context}

            Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:"""

            response = self.llm.invoke(prompt)

            return {
                "answer": response.content,
                "source_documents": all_docs[:3]
            }

        except Exception as e:
            logger.error(f"Error processing query: {str(e)}")
            return {
                "answer": "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø¤Ø§Ù„.",
                "source_documents": []
            }

    def merge_collections(self, collection_ids: List[str]) -> Optional[str]:
        """
        Merge multiple collections into a new one.
        
        Args:
            collection_ids: List of collection IDs to merge
            
        Returns:
            New collection ID if successful, None otherwise
        """
        try:
            # Validate collections exist
            collections = []
            for cid in collection_ids:
                if cid in self.active_collections:
                    collections.append(self.active_collections[cid])
                else:
                    raise ValueError(f"Collection not found: {cid}")

            # Create new collection ID
            merged_id = f"merged_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            merged_path = self.base_path / "chroma_db" / merged_id

            # Get all documents from collections
            all_texts = []
            all_metadata = []
            
            for vectorstore in collections:
                docs = vectorstore.get()
                all_texts.extend(docs['documents'])
                all_metadata.extend(docs['metadatas'])

            # Create new merged collection
            merged_vectorstore = Chroma.from_texts(
                texts=all_texts,
                metadatas=all_metadata,
                embedding=self.doc_processor.embeddings,
                persist_directory=str(merged_path)
            )

            # Add to active collections
            self.active_collections[merged_id] = merged_vectorstore

            return merged_id

        except Exception as e:
            logger.error(f"Error merging collections: {str(e)}")
            return None

    def remove_collection(self, collection_id: str) -> bool:
        """
        Remove a collection from the system.

        Args:
            collection_id: ID of the collection to remove

        Returns:
            bool: True if successful, False otherwise
        """
        print(f"Attempting to remove collection: {collection_id}")
        try:
            if collection_id in self.active_collections:
                # Remove from active collections
                del self.active_collections[collection_id]

                # Remove directory
                collection_path = self.base_path / "chroma_db" / collection_id
                if collection_path.exists():
                    import shutil
                    shutil.rmtree(str(collection_path))
                    print(f"Removed collection directory: {collection_path}")
                else:
                    print(f"Collection directory not found: {collection_path}")

                logger.info(f"Removed collection: {collection_id}")
                return True
            else:
                logger.warning(f"Collection not found in active collections: {collection_id}")
                return False

        except Exception as e:
            logger.error(f"Error removing collection: {str(e)}")
            return False

    def get_active_collections(self) -> List[Dict[str, Any]]:
        """
        Get information about all active collections.
        
        Returns:
            List of collection information dictionaries
        """
        try:
            collections_info = []
            for cid, vectorstore in self.active_collections.items():
                try:
                    docs = vectorstore.get()
                    collections_info.append({
                        "collection_id": cid,
                        "document_count": len(docs['documents']),
                        "created": datetime.fromtimestamp(
                            (self.base_path / "chroma_db" / cid).stat().st_ctime
                        ).isoformat()
                    })
                except Exception as e:
                    logger.error(f"Error getting info for collection {cid}: {str(e)}")
                    
            return collections_info
            
        except Exception as e:
            logger.error(f"Error getting collections info: {str(e)}")
            return []
        
    def remove_collection(self, collection_id: str) -> bool:
        """
        Remove a collection from the system.

        Args:
            collection_id: ID of the collection to remove

        Returns:
            bool: True if successful, False otherwise
        """
        print(f"Attempting to remove collection: {collection_id}")
        try:
            if collection_id in self.active_collections:
                # Remove from active collections
                del self.active_collections[collection_id]

                # Remove directory
                collection_path = self.base_path / "chroma_db" / collection_id
                if collection_path.exists():
                    import shutil
                    shutil.rmtree(str(collection_path))
                    print(f"Removed collection directory: {collection_path}")
                else:
                    print(f"Collection directory not found: {collection_path}")

                logger.info(f"Removed collection: {collection_id}")
                return True
            else:
                logger.warning(f"Collection not found in active collections: {collection_id}")
                return False

        except Exception as e:
            logger.error(f"Error removing collection: {str(e)}")
            return False
</file>

<file path="requirements.txt">
# Core dependencies
flask>=2.0.0
flask-cors>=4.0.0
python-dotenv>=0.19.0

# Document processing
python-docx>=0.8.11
pypdf>=3.0.0

# LangChain and AI
langchain>=0.1.0
langchain-google-genai>=0.0.5
google-generativeai>=0.3.0
chromadb>=0.4.14

# Vector stores and embeddings
sentence-transformers>=2.2.2

# Data handling
pandas>=2.0.0
numpy>=1.21.0

# Utilities
pathlib>=1.0.1
python-dateutil>=2.8.2
werkzeug>=2.0.0

# Optional: for proper Arabic text handling
arabic-reshaper>=3.0.0
python-bidi>=0.4.2

langchain_community
gunicorn==21.2.0
openai>=1.0.0
langchain_openai
</file>

<file path="test_agent.py">
# test_agent.py
import os
from agent import HRAgent  # Assuming your agent is in agent.py
from dotenv import load_dotenv


def test_hr_agent(
    google_api_key: str,
    vacations_file: str,
    tickets_file: str,
    test_queries: list,
):
    """Tests the HR agent with a set of queries.

    Args:
        google_api_key: Google API key.
        vacations_file: Path to the vacations CSV file.
        tickets_file: Path to the tickets CSV file.
        test_queries: A list of test queries.
    """
    try:
        agent = HRAgent(
            google_api_key=google_api_key,
            vacations_file=vacations_file,
            tickets_file=tickets_file,
        )

        results = {}
        for query in test_queries:
            print(f"\nQuery: {query}")
            response = agent.process_query(query, employee_id="1001")  # Replace with a test employee ID
            print(f"Response: {response}")
            results[query] = response

        return results

    except Exception as e:
        print(f"Error during testing: {str(e)}")
        return {}

if __name__ == "__main__":
    load_dotenv()
    UPLOAD_FOLDER = 'data/documents'
    ALLOWED_EXTENSIONS = {'pdf', 'docx', 'doc', 'txt'} 
    GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
    VACATIONS_FILE = "data/vacations.csv"
    TICKETS_FILE = "data/tickets.csv"

    TEST_QUERIES = [
        "Ù…Ø§ Ù‡ÙŠ Ø´Ø±ÙˆØ· Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù† Ø¨Ø¹Ø¯ØŸ",
        "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù† Ø¨Ø¹Ø¯ Ø¨Ø´ÙƒÙ„ Ø¯Ø§Ø¦Ù…ØŸ",
        "Ù…Ø§ Ù‡ÙŠ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø·Ù„Ø¨ Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù† Ø¨Ø¹Ø¯ØŸ",
        "Ù‡Ù„ ÙŠØ¬Ø¨ Ø¹Ù„ÙŠ ØªÙˆÙÙŠØ± Ø§Ù„ØªØ¬Ù‡ÙŠØ²Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨ÙŠ Ù„Ù„Ø¹Ù…Ù„ Ø¹Ù† Ø¨Ø¹Ø¯ØŸ",
        "ÙƒÙŠÙ ÙŠØªÙ… ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ† Ø§Ù„Ø°ÙŠÙ† ÙŠØ¹Ù…Ù„ÙˆÙ† Ø¹Ù† Ø¨Ø¹Ø¯ØŸ",
        "Ù…Ø§ Ù‡ÙŠ Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ø´Ø±ÙƒØ© Ø¨Ø´Ø£Ù† Ø£Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù† Ø¨Ø¹Ø¯ØŸ",
        "Ù‡Ù„ ÙŠÙˆØ¬Ø¯ ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù† Ø¨Ø¹Ø¯ØŸ",
        "ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ Ø¥Ø°Ø§ ÙˆØ§Ø¬Ù‡Øª Ù…Ø´Ø§ÙƒÙ„ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù† Ø¨Ø¹Ø¯ØŸ",
        "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù† Ø¨Ø¹Ø¯ Ù…Ù† Ø®Ø§Ø±Ø¬ Ø§Ù„Ø¨Ù„Ø§Ø¯ØŸ",
        "Ù…Ø§ Ù‡ÙŠ Ù…Ø¯Ø© Ø§Ù„Ø¥Ø¬Ø§Ø²Ø© Ø§Ù„Ø³Ù†ÙˆÙŠØ©ØŸ",
    ]

    test_results = test_hr_agent(
        GOOGLE_API_KEY, VACATIONS_FILE, TICKETS_FILE, TEST_QUERIES
    )

    # You can add further processing or analysis of the test_results dictionary here
    # For example, save the results to a file or calculate metrics

    # Print the results in a structured way for analysis:
    print("\n\n----- Test Results -----")
    for query, response in test_results.items():
        print(f"\nQuery: {query}")
        print(f"Response: {response}")
</file>

<file path="tree.py">
import os

def generate_folder_tree(directory):
    """
    Generates a tree-like representation of a directory and its contents.

    Args:
        directory: The path to the directory.

    Returns:
        A string representing the directory tree.
    """

    tree_str = ""
    for root, dirs, files in os.walk(directory):
        level = root.replace(directory, '').count(os.sep)
        indent = ' ' * 4 * level
        tree_str += '{}{}/\n'.format(indent, os.path.basename(root))
        subindent = ' ' * 4 * (level + 1)
        for f in files:
            tree_str += '{}{}\n'.format(subindent, f)

    return tree_str

if __name__ == "__main__":
    folder_path = input("Enter the folder directory: ")

    if os.path.isdir(folder_path):
        tree = generate_folder_tree(folder_path)
        print(tree)
    else:
        print("Invalid directory path.")
</file>

<file path="data\chat_history_1001.json">
[
  {
    "id": "1",
    "content": "Ù…Ø§ Ù‡ÙŠ Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù† Ø¨Ø¹Ø¯ØŸ",
    "type": "user",
    "timestamp": "2025-01-05T12:29:03.135116",
    "status": "sent"
  },
  {
    "id": "3",
    "content": "The provided policy document does not contain information about remote work policy. Please visit www.hrsd.gov.sa for this information.",
    "type": "bot",
    "timestamp": "2025-01-05T12:29:03.135116",
    "status": "sent"
  },
  {
    "id": "3",
    "content": "Ù…Ø§ Ù‡Ùˆ Ù†Øµ Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ø§ÙˆÙ„Ù‰",
    "type": "user",
    "timestamp": "2025-01-05T12:30:09.986223",
    "status": "sent"
  },
  {
    "id": "5",
    "content": "The text of the first article is:\n\n\"Council of Civil Service Resolution No. 1/1364, dated 18/10/1429 AH, stipulates that (compensation for those appointed under the wages clause in government agencies upon termination of their service for their accrued leave that they have not enjoyed - in accordance with Article (111) of the Labor System issued by Royal Decree No. (M51) dated 22/8/1426 AH, and Article (111) referred to stipulates that (the employee has the right to receive his wages for the days of accrued leave if he leaves work before using it, for the period for which he has not received his leave).\"",
    "type": "bot",
    "timestamp": "2025-01-05T12:30:09.986223",
    "status": "sent"
  },
  {
    "id": "5",
    "content": "what is my vacation balance",
    "type": "user",
    "timestamp": "2025-01-05T12:32:16.786455",
    "status": "sent"
  },
  {
    "id": "7",
    "content": "Your current vacation balance is 14 days.",
    "type": "bot",
    "timestamp": "2025-01-05T12:32:16.786455",
    "status": "sent"
  },
  {
    "id": "7",
    "content": "genearet a ticket for 10 days vacation",
    "type": "user",
    "timestamp": "2025-01-05T12:32:47.086471",
    "status": "sent"
  },
  {
    "id": "9",
    "content": "Your vacation request for 10 days (March 1st to March 10th, 2024) has been successfully created. Your ticket ID is VT2025016.",
    "type": "bot",
    "timestamp": "2025-01-05T12:32:47.086471",
    "status": "sent"
  },
  {
    "id": "9",
    "content": "genearet a ticket for 10 days vacation",
    "type": "user",
    "timestamp": "2025-01-05T14:15:54.155680",
    "status": "sent"
  },
  {
    "id": "11",
    "content": "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.",
    "type": "bot",
    "timestamp": "2025-01-05T14:15:54.155680",
    "status": "sent"
  },
  {
    "id": "11",
    "content": "tell me all what you know about me",
    "type": "user",
    "timestamp": "2025-01-05T14:15:55.731862",
    "status": "sent"
  },
  {
    "id": "13",
    "content": "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.",
    "type": "bot",
    "timestamp": "2025-01-05T14:15:55.731862",
    "status": "sent"
  },
  {
    "id": "13",
    "content": "genearet a ticket for 10 days vacation",
    "type": "user",
    "timestamp": "2025-01-05T15:08:53.408378",
    "status": "sent"
  },
  {
    "id": "15",
    "content": "Your vacation request (VT2025017) has been successfully created.  You requested 10 days of vacation from March 15th to March 24th, 2024. ",
    "type": "bot",
    "timestamp": "2025-01-05T15:08:53.408378",
    "status": "sent"
  }
]
</file>

<file path="tools\rag_tool.py">
# tools/rag_tool.py
from typing import Dict, List, Optional
import os
from rag_system import HRRAGSystem

class RAGTool:
    """Tool for handling HR document queries using RAG system"""
    
    def __init__(self, google_api_key: str, openai_api_key: str):
        """Initialize RAG Tool with configurations."""
        self.google_api_key = google_api_key
        self.openai_api_key = openai_api_key
        self.rag_system = HRRAGSystem(google_api_key, openai_api_key)
        self.active_docs = []

    def query(self, question: str) -> str:
        """Query the RAG system with a question."""
        try:
            response = self.rag_system.query(question)
            return response.get('answer', 'Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£Ø³ØªØ·Ø¹ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù†Ø§Ø³Ø¨Ø©.')
        except Exception as e:
            print(f"Error in RAG query: {str(e)}")
            return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø¤Ø§Ù„."

    def add_document(self, filepath: str) -> bool:
        """Add a new document to the RAG system."""
        try:
            collection_id = self.rag_system.process_document(filepath)
            if collection_id:
                self.active_docs.append(filepath)
                return True
            return False
        except Exception as e:
            print(f"Error adding document: {str(e)}")
            return False

    def update_active_documents(self, document_list: List[str]) -> bool:
        """Update which documents are active in the system."""
        try:
            # Process any new documents
            for doc in document_list:
                if doc not in self.active_docs:
                    self.add_document(doc)
            
            # Update active documents
            self.active_docs = document_list
            return True
        except Exception as e:
            print(f"Error updating active documents: {str(e)}")
            return False
        
    def reinitialize_rag_system(self):
        """Reinitializes the RAG system."""
        self.rag_system = HRRAGSystem(self.google_api_key, self.openai_api_key)
        print("RAG system reinitialized.")
</file>

<file path="tools\support_ticket_tool.py">
# tools/support_ticket_tool.py
import pandas as pd
import uuid
from datetime import datetime
from typing import Dict

class SupportTicketTool:
    """Tool for creating general support tickets."""

    def __init__(self, tickets_file: str):
        """Initialize Support Ticket Tool with the CSV file path."""
        self.tickets_file = tickets_file
        self._ensure_file_exists()

    def _ensure_file_exists(self):
        """Create support tickets file if it doesn't exist."""
        try:
            pd.read_csv(self.tickets_file)
        except FileNotFoundError:
            df = pd.DataFrame(columns=[
                'ticket_id', 'employee_id', 'summary', 'description',
                'status', 'created_at', 'updated_at'
            ])
            df.to_csv(self.tickets_file, index=False)

    def _generate_ticket_id(self) -> str:
        """Generate a unique ticket ID using UUID."""
        return f"ST-{uuid.uuid4().hex[:8].upper()}"

    def create_ticket(self, employee_id: str, summary: str, description: str) -> Dict:
        """Create a new support ticket.

        Args:
            employee_id: The ID of the employee creating the ticket.
            summary: A brief summary of the issue.
            description: A more detailed description of the issue.

        Returns:
            A dictionary containing the status of the operation and a message.
        """
        try:
            new_ticket = {
                'ticket_id': self._generate_ticket_id(),
                'employee_id': employee_id,
                'summary': summary,
                'description': description,
                'status': 'open',
                'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'updated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }

            df = pd.read_csv(self.tickets_file)
            new_ticket_df = pd.DataFrame([new_ticket])
            df = pd.concat([df, new_ticket_df], ignore_index=True)
            df.to_csv(self.tickets_file, index=False)

            return {
                "status": "success",
                "message": "Support ticket created successfully.",
                "ticket_id": new_ticket['ticket_id']
            }

        except Exception as e:
            print(f"Error creating support ticket: {str(e)}")
            return {
                "status": "error",
                "message": "Failed to create support ticket."
            }
</file>

<file path="tools\ticket_tool.py">
# tools/ticket_tool.py
import pandas as pd
from datetime import datetime
from typing import Dict
import json

class TicketTool:
    """Tool for managing vacation request tickets"""
    
    def __init__(self, tickets_file: str):
        """Initialize Ticket Tool with the CSV file path."""
        self.tickets_file = tickets_file
        self._ensure_file_exists()

    def _ensure_file_exists(self):
        """Create tickets file if it doesn't exist."""
        try:
            df = pd.read_csv(self.tickets_file)
        except FileNotFoundError:
            # Create new file with structure
            df = pd.DataFrame(columns=[
                'ticket_id', 'employee_id', 'request_type',
                'start_date', 'end_date', 'days_count',
                'status', 'manager_id', 'request_date',
                'response_date', 'notes'
            ])
            df.to_csv(self.tickets_file, index=False)

    def _generate_ticket_id(self) -> str:
        """Generate a unique ticket ID."""
        try:
            df = pd.read_csv(self.tickets_file)
            if df.empty:
                return f"VT{datetime.now().year}001"
            
            # Get last ticket number and increment
            last_ticket = df['ticket_id'].iloc[-1]
            ticket_num = int(last_ticket[-3:]) + 1
            return f"VT{datetime.now().year}{ticket_num:03d}"
            
        except Exception:
            # Fallback to timestamp-based ID
            return f"VT{datetime.now().strftime('%Y%m%d%H%M%S')}"

    def create_ticket(self, employee_id: str, start_date: str, end_date: str, request_type: str, notes: str = "") -> Dict:
        """Create a new vacation request ticket."""
        try:
            # No need for JSON parsing anymore
            days_count = (datetime.strptime(start_date,'%Y-%m-%d') - datetime.strptime(end_date, '%Y-%m-%d')).days + 1

            new_ticket = {
                'ticket_id': self._generate_ticket_id(),
                'employee_id': employee_id,
                'request_type': request_type,
                'start_date': start_date,
                'end_date': end_date,
                'days_count': days_count,
                'status': 'pending',
                'manager_id': None,
                'request_date': datetime.now().strftime('%Y-%m-%d'),
                'response_date': None,
                'notes': notes
            }
            
            # Add to CSV
            df = pd.read_csv(self.tickets_file)
            df = pd.concat([df, pd.DataFrame([new_ticket])], ignore_index=True)
            df.to_csv(self.tickets_file, index=False)
            
            return {
                "status": "success",
                "message": "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø·Ù„Ø¨ Ø§Ù„Ø¥Ø¬Ø§Ø²Ø© Ø¨Ù†Ø¬Ø§Ø­",
                "ticket_id": new_ticket['ticket_id']
            }
            
        except Exception as e:
            print(f"Error creating ticket: {str(e)}")
            return {
                "error": "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø·Ù„Ø¨ Ø§Ù„Ø¥Ø¬Ø§Ø²Ø©",
                "status": "error"
            }

    def update_ticket_status(self, ticket_id: str, status: str, 
                           manager_id: str, notes: str = "") -> Dict:
        """Update the status of a ticket."""
        try:
            df = pd.read_csv(self.tickets_file)
            mask = df['ticket_id'] == ticket_id
            
            if not any(mask):
                return {
                    "error": "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø·Ù„Ø¨",
                    "status": "not_found"
                }
            
            # Update ticket
            df.loc[mask, 'status'] = status
            df.loc[mask, 'manager_id'] = manager_id
            df.loc[mask, 'response_date'] = datetime.now().strftime('%Y-%m-%d')
            if notes:
                df.loc[mask, 'notes'] = notes
            
            # Save changes
            df.to_csv(self.tickets_file, index=False)
            
            return {
                "status": "success",
                "message": "ØªÙ… ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø·Ù„Ø¨ Ø¨Ù†Ø¬Ø§Ø­"
            }
            
        except Exception as e:
            print(f"Error updating ticket: {str(e)}")
            return {
                "error": "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø·Ù„Ø¨",
                "status": "error"
            }

    def get_employee_tickets(self, employee_id: str) -> Dict:
        """Get all tickets for an employee."""
        try:
            df = pd.read_csv(self.tickets_file)
            employee_tickets = df[df['employee_id'] == employee_id].to_dict('records')
            
            return {
                "status": "success",
                "tickets": employee_tickets
            }
            
        except Exception as e:
            print(f"Error getting tickets: {str(e)}")
            return {
                "error": "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø·Ù„Ø¨Ø§Øª",
                "status": "error"
            }
</file>

<file path="tools\vacation_tool.py">
# tools/vacation_tool.py
import pandas as pd
from typing import Dict
from datetime import datetime

class VacationTool:
    """Tool for checking and managing employee vacation balances"""
    
    def __init__(self, vacations_file: str):
        """Initialize Vacation Tool with the CSV file path."""
        self.vacations_file = vacations_file
        self._ensure_file_exists()

    def _ensure_file_exists(self):
        """Create vacations file if it doesn't exist."""
        try:
            df = pd.read_csv(self.vacations_file)
        except FileNotFoundError:
            # Create new file with structure
            df = pd.DataFrame(columns=[
                'employee_id', 'name', 'position', 'department',
                'annual_balance', 'used_days', 'remaining_balance',
                'last_updated'
            ])
            df.to_csv(self.vacations_file, index=False)

    def check_balance(self, employee_id: str) -> Dict:
        """Check vacation balance for an employee."""
        try:
            df = pd.read_csv(self.vacations_file)
            employee = df[df['employee_id'] == int(employee_id)]
            
            if employee.empty:
                return {
                    "error": "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ¸Ù",
                    "status": "not_found"
                }
            
            return {
                "status": "success",
                "employee_id": str(employee_id),
                "name": employee.iloc[0]['name'],
                "annual_balance": float(employee.iloc[0]['annual_balance']),
                "used_days": float(employee.iloc[0]['used_days']),
                "remaining_balance": float(employee.iloc[0]['remaining_balance']),
                "last_updated": employee.iloc[0]['last_updated']
            }
            
        except Exception as e:
            print(f"Error checking balance: {str(e)}")
            return {
                "error": "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±ØµÙŠØ¯",
                "status": "error"
            }

    def update_balance(self, employee_id: str, days_used: float) -> Dict:
        """Update vacation balance after request approval."""
        try:
            df = pd.read_csv(self.vacations_file)
            mask = df['employee_id'] == int(employee_id)
            
            if not any(mask):
                return {
                    "error": "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ¸Ù",
                    "status": "not_found"
                }
            
            # Update balance
            df.loc[mask, 'used_days'] += days_used
            df.loc[mask, 'remaining_balance'] -= days_used
            df.loc[mask, 'last_updated'] = datetime.now().strftime('%Y-%m-%d')
            
            # Save changes
            df.to_csv(self.vacations_file, index=False)
            
            return {
                "status": "success",
                "message": "ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø±ØµÙŠØ¯ Ø¨Ù†Ø¬Ø§Ø­"
            }
            
        except Exception as e:
            print(f"Error updating balance: {str(e)}")
            return {
                "error": "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø±ØµÙŠØ¯",
                "status": "error"
            }
</file>

<file path="tools\__init__.py">
# tools/__init__.py

from .rag_tool import RAGTool
from .vacation_tool import VacationTool
from .ticket_tool import TicketTool
from .support_ticket_tool import SupportTicketTool

__all__ = [
    'RAGTool',
    'VacationTool',
    'TicketTool',
    'SupportTicketTool'
]
</file>

</repository_files>
